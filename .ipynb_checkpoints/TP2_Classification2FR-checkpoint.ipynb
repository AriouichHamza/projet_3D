{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLsensyrZsJS"
   },
   "source": [
    "# TP: Machine Learning\n",
    "\n",
    "## TP2: Classification (4h) \n",
    "\n",
    "En apprentissage automatique, la classification est liée aux approches d’apprentissage supervisé\n",
    "dans lesquelles l’algorithme s’adapte à partir d’un ensemble de données annotées. Cette phase d’ap-\n",
    "prentissage est suivie d’une validation phase pour évaluer le modèle de classification à travers plu-\n",
    "sieurs métriques. Une fois le modèle correctement validée, une phase de généralisation permet de\n",
    "classer les nouvelles données. L’ensemble de données fourni a été produit par l’Organisation Mon-\n",
    "diale de la Santé (OMS). Il a mutualisé l’évolution de 20 longs métrages depuis 15 ans et dans de\n",
    "nombreux pays. L’un des objectifs de ce TP est de comprendre l’espace des caractéristiques et es-\n",
    "sayer de prédire le développement des pays. \n",
    "\n",
    "**Objectifs :**\n",
    "\n",
    "- Visualiser l’espace des caractéristiques.\n",
    "- Discuter de la séparabilité des données dans l’espace des caractéristiques.\n",
    "- Normaliser les ensembles de données.\n",
    "- Former un K-NN, un arbre de décision, une forêt aléatoire et un SVM.\n",
    "- Visualisez la frontiere de décision pour chaque méthode.\n",
    "- Créer un ensemble de données de test.\n",
    "- Calculer les scores AUC sur un ensemble de données d’évaluation.\n",
    "- Ajuster les hyperparamètres.\n",
    "- Visualiser la modification de la frontiere de décision pour chaque réglage.\n",
    "- Discutez des limites des quatre implémentations des modèles.\n",
    "\n",
    "Le notebook correspondant à ce TP est disponible sur Moodle. Répondez aux questions directement\n",
    "sur ce notebook. Le notebook doit être remis avant la prochaine session. Le travail peut être fait en\n",
    "binôme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5dSubbebJQ-"
   },
   "source": [
    "## 1 : Visualisation de l’espace des caractéristiques\n",
    "Vous travaillerez sur le jeu de données de l’OMS en l’an 2000. Cette première étape consiste à choisir\n",
    "deux caractéristiques pour effectuer une classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvpYb9asOaCN"
   },
   "source": [
    "**À faire 1.1**\n",
    "\n",
    "Exécutez les cellules suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "rDNpZKEOO85F",
    "ExecuteTime": {
     "end_time": "2023-11-29T10:42:06.119133500Z",
     "start_time": "2023-11-29T10:42:06.039491900Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolors\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"Life_Expectancy_Data.csv\")\n",
    "df = df.dropna()\n",
    "df.info()\n",
    "\n",
    "df1 = df[(df.Year == 2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df.Status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df[(df.Status == \"Developed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "DzPeL_7xd5BC",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_X = df1[['Total_expenditure', 'BMI']]\n",
    "df_Status = df1[['Status']]\n",
    "\n",
    "df_Y = df_Status.replace(['Developing', 'Developed'], [0, 1])\n",
    "\n",
    "np1 = df_X.to_numpy()\n",
    "plt.scatter(np1[:,0], np1[:,1], c=np.squeeze(df_Y.to_numpy()), cmap=matplotlib.colors.ListedColormap(['red', 'green']))\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WR1CNuNOTSgI"
   },
   "source": [
    "**QUESTION 1**\n",
    "\n",
    "Pourquoi le statut du label a-t-il été binarisé ?\n",
    "\n",
    "Cet espace de caractéristiques est-il facilement séparable ? Justifiez votre réponse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUmhMbD4TlBg"
   },
   "source": [
    "**À coder 1.2**\n",
    "\n",
    "Tracer les dépenses totales (Expenditure) par rapport à la scolarité (Schooling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "SpfTKctFh3ro",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df1['Schooling'], df1['Total_expenditure'],  c=np.squeeze(df_Y.to_numpy()), cmap=matplotlib.colors.ListedColormap(['red', 'green']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqvWF2ZOT6fV"
   },
   "source": [
    "**À coder 1.3**\n",
    "\n",
    "Tracez l’espérance de vie (Life Expectancy) à la scolarité (Schooling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Pbz2jUJMh53f",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df1['Schooling'], df1['Life_expectancy'],  c=np.squeeze(df_Y.to_numpy()), cmap=matplotlib.colors.ListedColormap(['red', 'green']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1imRRQoUPer"
   },
   "source": [
    "**QUESTION 2**\n",
    "\n",
    "Quelles seraient les meilleures caractéristiques à utiliser ? Justifiez votre réponse.\n",
    "\n",
    "La meuilleur caracteristique a utiliser est l'espérance de vie car les points sont plus separable que l'expension.\n",
    "\n",
    "Utilisez ces caractéristiques en tant que df_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8J_HeM0wNY93"
   },
   "source": [
    "##  2: Normalisation des ensembles de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLIqbScfUyl1"
   },
   "source": [
    "Pour classer, les valeurs de l’ensemble de données d’apprentissage doivent être normalisées (c’est-\n",
    "à-dire entre 0 et 1). Cette normalisation peut être effectuée de différentes manières."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqxQ6NrnVNsE"
   },
   "source": [
    "**À coder 2.1**\n",
    "\n",
    "Normalisez df_X. Cette normalisation doit parfaitement encadrer les données (c’est-à-dire que les\n",
    "valeurs minimales et maximales de chaque caractéristique doivent être respectivement 0 et 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "CK613akYqrGD",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_X = df1[['Schooling', 'Life_expectancy']]\n",
    "\n",
    "np_Y = df_Y.to_numpy().squeeze()\n",
    "\n",
    "print(np_Y.shape)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "np_X_norm = scaler.fit_transform(df_X.to_numpy())\n",
    "\n",
    "# df_X_norm = pd.DataFrame(np_X_norm, columns=['Schooling', 'Life_expectancy'])\n",
    "\n",
    "print(np_X_norm)\n",
    "\n",
    "plt.scatter(np_X_norm[:,0], np_X_norm[:,1], c=np.squeeze(np_Y), cmap=matplotlib.colors.ListedColormap(['red', 'green']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ur1yR4XpX6xq"
   },
   "source": [
    "**À faire 2.2**\n",
    "\n",
    "Chacune des cellules suivantes effectue une étape d’apprentissage et un calcul des scores AUC.\n",
    "Pour chaque classificateur, plusieurs paramètres ont été choisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Tv_3eMSrDszE",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf1.fit(np_X_norm, np_Y)\n",
    "\n",
    "np_Y_pred = clf1.predict_proba(np_X_norm)\n",
    "print(np_Y_pred.shape)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "bkJdVdMf-6Ay",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf2 = SVC(C=2.0, kernel='linear', probability=True)\n",
    "clf2.fit(np_X_norm, np_Y)\n",
    "\n",
    "np_Y_pred = clf2.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "iBPKA7Sg-agW",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf3 = DecisionTreeClassifier(max_depth=3)\n",
    "clf3.fit(np_X_norm, np_Y)\n",
    "\n",
    "np_Y_pred = clf3.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "nmhnBCUx_Q6X",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf4 = RandomForestClassifier(n_estimators=100, max_depth=3)\n",
    "clf4.fit(np_X_norm, np_Y)\n",
    "\n",
    "np_Y_pred = clf4.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKYdS0KNZSUQ"
   },
   "source": [
    "**QUESTION 3**\n",
    "\n",
    "Identifiez chaque classificateur et spécifiez les paramètres utilisés.\n",
    "\n",
    "Classifier 1 : KNN, se basant sur 5 voisins\n",
    "Classifier 2 : SVM, se basant sur un noyau linéaire\n",
    "Classifier 3: Decision Tree, se basant sur une profondeur de 3 neouds\n",
    "Classifier 4 : Random Forest, se basant sur 100 arbres d'une profondeur de 3 noeuds\n",
    "\n",
    "\n",
    "\n",
    "Décrire et expliquer les résultats obtenus pour chaque courbe ROC. Quelle est la relation entre l’AUC\n",
    "et la courbe ROC ? D’après la courbe ROC, quel modèle est le meilleur si l’on veut maximiser la sen-\n",
    "sibilité ? Et si on veut maximiser la spécificité ? Comparez ces résultats avec l’AUC.\n",
    "\n",
    "L'AUC est est l'aire sous la courbe du ROC, plus il est proche de 1, plus le classifieur est performant.\n",
    "\n",
    "Pour le problème de classification binaire, la limite de décision est une hypersurface qui divise l’es-\n",
    "pace des fonctionnalités entre deux ensembles (pour chaque classe). Ensuite, cette surface est\n",
    "composée de tous les points d’équiprobabilité dans l’espace des caractéristiques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTclWyVibVDe"
   },
   "source": [
    "**À faire 2.3**\n",
    "\n",
    "Tracez la limite de décision avec df_X pour chaque classificateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "GeGb5-Oc6PxC",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "x_min, x_max = np_X_norm[:, 0].min() - 0.1, np_X_norm[:, 0].max() + 0.1\n",
    "y_min, y_max = np_X_norm[:, 1].min() - 0.1, np_X_norm[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(2, 2, sharex='col', sharey='row', figsize=(10, 8))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1], [0, 1]),\n",
    "                        [clf1, clf2, clf3, clf4],\n",
    "                        ['KNN', 'Linear SVM', 'Decision Tree', 'Random Forest']):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "\n",
    "    axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0], idx[1]].scatter(np_X_norm[:, 0], np_X_norm[:, 1], c=np_Y,\n",
    "                                  s=20, edgecolor='k')\n",
    "    axarr[idx[0], idx[1]].set_title(tt)\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N26rAHblbpMw"
   },
   "source": [
    "**QUESTION 4**\n",
    "\n",
    "Quel est le principal problème de l’étape de classification avec cet ensemble de données ?\n",
    "À votre avis, quel classificateur est le mieux adapté à cette tâche de classification ? Justifiez votre\n",
    "réponse.\n",
    "\n",
    "Les donnees sont melangées et il n'y a pas de frontiere de decision claire.\n",
    "\n",
    "L'arbre de decision et la foret aleatoire semble etre les plus adaptés car ils ont un meuilleur score AUC et ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIan8C5HG1EC"
   },
   "source": [
    "## 3: Correction des biais et réglages des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIy42WrbmKTB"
   },
   "source": [
    "Dans cette partie, vous vous concentrerez sur l’amélioration des scores AUC des quatre méthodes.\n",
    "\n",
    "Tout d’abord, vous peserez les classes pour équilibrer la prédiction du classificateur. Ensuite, vous\n",
    "ajusterez divers hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWkUR2dFmk3e"
   },
   "source": [
    "**À coder 3.1**\n",
    "\n",
    "Calculez le pourcentage de classe ”Developed” dans df_Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Gk8uStv2l5cj",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(\"Le pourcentage de 'Developed' dans df_Y est de : {} %\".format(np_Y.sum()/np_Y.shape[0]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PErx0dejnKBY"
   },
   "source": [
    "Les algorithmes SVM, Decision Tree et Random Forest ont un paramètre nommé : class_weight.\n",
    "Voici un extrait de la documentation sklearn :\n",
    "\n",
    "class_weight dict, list of dict or “balanced”, default=None\n",
    "\n",
    "Poids associés aux classes sous la forme class_label:weight. Si aucun, toutes les classes sont cen-\n",
    "sées avoir un poids de un. Pour les problèmes multi-sorties, une liste de dicts peut être fournie dans\n",
    "le même ordre que les colonnes de y.\n",
    "\n",
    "Le mode « équilibré » (“balanced”) utilise les valeurs de y pour ajuster automatiquement les poids\n",
    "inversement proportionnels aux fréquences de classe dans les données d’entrée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_G6So0vnr0c"
   },
   "source": [
    "**QUESTION 5**\n",
    "\n",
    "Quel serait le poids pour chaque classe ?\n",
    "\n",
    "Idealement, le poids pour Developed serait de 0.21 et le poids pour Developing serait de 0.79."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewqT7btZn07G"
   },
   "source": [
    "**À coder 3.2**\n",
    "\n",
    "Équilibrez le classificateur SVM, Decision Tree et Random Forest et tracez les limites de décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "x33o_f4Pn_mW",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "clf2 = SVC(C=2.0, kernel='linear', probability=True, class_weight='balanced')\n",
    "clf2.fit(np_X_norm, np_Y)\n",
    "\n",
    "print(clf2.class_weight_)\n",
    "\n",
    "np_Y_pred = clf2.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "clf3 = DecisionTreeClassifier(max_depth=3, class_weight='balanced')\n",
    "clf3.fit(np_X_norm, np_Y)\n",
    "\n",
    "\n",
    "np_Y_pred = clf3.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "clf4 = RandomForestClassifier(n_estimators=100, max_depth=3)\n",
    "clf4.fit(np_X_norm, np_Y)\n",
    "\n",
    "\n",
    "np_Y_pred = clf4.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbnKAcElsqI7"
   },
   "source": [
    "**À coder 3.3**\n",
    "\n",
    "Calculez le nouveau score AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Dkpm3R9Dsvon",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = np_X_norm[:, 0].min() - 0.1, np_X_norm[:, 0].max() + 0.1\n",
    "y_min, y_max = np_X_norm[:, 1].min() - 0.1, np_X_norm[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "f, axarr = plt.subplots(1, 3, sharex='col', sharey='row', figsize=(14, 6))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1, 2]),\n",
    "                        [clf2, clf3, clf4],\n",
    "                        [ 'Linear SVM', 'Decision Tree', 'Random Forest']):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    axarr[idx[0]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0]].scatter(np_X_norm[:, 0], np_X_norm[:, 1], c=np_Y,\n",
    "                                  s=20, edgecolor='k')\n",
    "    axarr[idx[0]].set_title(tt)\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qInghzh8sxzX"
   },
   "source": [
    "**QUESTION 6**\n",
    "\n",
    "Les scores de l’AUC ont-ils augmenté ? Comment l’interprètez-vous ?\n",
    "\n",
    "Selon vous, l’équilibre des classes a-t-il amélioré le classement ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwQR6dM2t2oD"
   },
   "source": [
    "Concentrons-nous sur le classificateur SVM.\n",
    "\n",
    "Sklearn autorise plusieurs noyaux.\n",
    "\n",
    "Voici un extrait de la documentation :\n",
    "\n",
    "**kernel** ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’, default=’rbf’\n",
    "\n",
    "Spécifie le type de noyau à utiliser dans l’algorithme. Il doit s’agir de «linear», «poly», «rbf», «sigmoïd»,\n",
    "« precomputed » ou appelable. Si aucun n’est donné, «rbf» sera utilisé. Si un appelable est donné, il\n",
    "est utilisé pour précalculer la matrice du noyau à partir des matrices de données ; cette matrice doit\n",
    "être un tableau de formes (n_samples, n_samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLGU5Itaue9g"
   },
   "source": [
    "**À coder 3.4**\n",
    "\n",
    "Testez les noyaux gaussiens (rbf) et polynomial avec un équilibrage des classes et affichez la fron-\n",
    "tière de décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "rx4bVVjrEuzw",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "clf2rbf = SVC(C=2.0, kernel='rbf', probability=True, class_weight='balanced')\n",
    "clf2rbf.fit(np_X_norm, np_Y)\n",
    "\n",
    "np_Y_pred = clf2rbf.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "clf2poly = SVC(C=2.0, kernel='poly', probability=True, class_weight='balanced')\n",
    "clf2poly.fit(np_X_norm, np_Y)\n",
    "\n",
    "np_Y_pred = clf2poly.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = np_X_norm[:, 0].min() - 0.1, np_X_norm[:, 0].max() + 0.1\n",
    "y_min, y_max = np_X_norm[:, 1].min() - 0.1, np_X_norm[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "f, axarr = plt.subplots(1, 3, sharex='col', sharey='row', figsize=(14, 6))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1, 2]),\n",
    "                        [clf2, clf2rbf, clf2poly],\n",
    "                        [ 'Linear SVM', 'rbf SVM', 'poly SVM']):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    axarr[idx[0]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0]].scatter(np_X_norm[:, 0], np_X_norm[:, 1], c=np_Y,\n",
    "                                  s=20, edgecolor='k')\n",
    "    axarr[idx[0]].set_title(tt)\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt7iX-ozuvOI"
   },
   "source": [
    "**QUESTION 7**\n",
    "\n",
    "Selon vous, quel est le meilleur noyau pour cet ensemble de données ? Justifiez votre réponse.\n",
    "\n",
    "Le noyeau ne change pas grand chose, le score AUC reste le meme. Pour la frontiere de decision, on remarque que les nouyeaux gaussien et polynomiale ne change pas grand choses.On en conclu que le noyeau lineaire suffit pour cet ensemble de donnees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vN-CbU-u-dd"
   },
   "source": [
    "**BONUS**\n",
    "\n",
    "Ajustez les paramètres des algorithmes d’arbre de décision et de forêt aléatoire et tracez les fron-\n",
    "tières de décision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "clf3up = DecisionTreeClassifier(max_depth=5, class_weight='balanced')\n",
    "clf3up.fit(np_X_norm, np_Y)\n",
    "\n",
    "\n",
    "np_Y_pred = clf3up.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "clf4up = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "clf4up.fit(np_X_norm, np_Y)\n",
    "\n",
    "\n",
    "np_Y_pred = clf4up.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = np_X_norm[:, 0].min() - 0.1, np_X_norm[:, 0].max() + 0.1\n",
    "y_min, y_max = np_X_norm[:, 1].min() - 0.1, np_X_norm[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "f, axarr = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(14, 6))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1]),\n",
    "                        [clf3up, clf4up],\n",
    "                        [ 'Decision tree 5 nods', 'Ramdom Forest 5 nods']):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    axarr[idx[0]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0]].scatter(np_X_norm[:, 0], np_X_norm[:, 1], c=np_Y,\n",
    "                                  s=20, edgecolor='k')\n",
    "    axarr[idx[0]].set_title(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e81rsBAYGu_3"
   },
   "source": [
    "En augmentent le nombre de noeuds, on augmente le score AUC jusqu'a 1. Cependant, la frontiere de decision semble assez bizarre. Il faudrait augmenter le nombre de données avant d'augmenter les performences du classifieur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69LKeU_ivUKr"
   },
   "source": [
    "This part is to test the generalization of your models.\n",
    "\n",
    "You trained several classifiers on two features extracted from the year 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3Y2PtfYwAJ6"
   },
   "source": [
    "**À coder 4.1**\n",
    "\n",
    "Appliquez vos modèles sur l’année 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Xpn4Pto-GusP",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df2 = df[(df.Year == 2012)]\n",
    "\n",
    "\n",
    "df_X = df2[['Schooling', 'Life_expectancy']]\n",
    "\n",
    "df_Y = df2['Status'].replace(['Developing', 'Developed'], [0, 1])\n",
    "\n",
    "np_Y = df_Y.to_numpy().squeeze()\n",
    "\n",
    "\n",
    "\n",
    "print(np_Y.shape)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "np_X_norm = scaler.fit_transform(df_X.to_numpy())\n",
    "\n",
    "# df_X_norm = pd.DataFrame(np_X_norm, columns=['Schooling', 'Life_expectancy'])\n",
    "\n",
    "print(np_X_norm)\n",
    "\n",
    "plt.scatter(np_X_norm[:,0], np_X_norm[:,1], c=np.squeeze(np_Y), cmap=matplotlib.colors.ListedColormap(['red', 'green']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "np_Y_pred = clf2.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "np_Y_pred = clf3.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "np_Y_pred = clf4.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = np_X_norm[:, 0].min() - 0.1, np_X_norm[:, 0].max() + 0.1\n",
    "y_min, y_max = np_X_norm[:, 1].min() - 0.1, np_X_norm[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "f, axarr = plt.subplots(1, 3, sharex='col', sharey='row', figsize=(14, 6))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1, 2]),\n",
    "                        [clf2, clf3, clf4],\n",
    "                        [ 'Linear SVM', 'Decision Tree', 'Random Forest']):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    axarr[idx[0]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0]].scatter(np_X_norm[:, 0], np_X_norm[:, 1], c=np_Y,\n",
    "                                  s=20, edgecolor='k')\n",
    "    axarr[idx[0]].set_title(tt)\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np_Y_pred = clf2.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "np_Y_pred = clf3.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "np_Y_pred = clf4.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = np_X_norm[:, 0].min() - 0.1, np_X_norm[:, 0].max() + 0.1\n",
    "y_min, y_max = np_X_norm[:, 1].min() - 0.1, np_X_norm[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "f, axarr = plt.subplots(1, 3, sharex='col', sharey='row', figsize=(14, 6))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1, 2]),\n",
    "                        [clf2, clf2rbf, clf2poly],\n",
    "                        [ 'Linear SVM', 'rbf SVM', 'poly SVM']):\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    axarr[idx[0]].contourf(xx, yy, Z, alpha=0.4)\n",
    "    axarr[idx[0]].scatter(np_X_norm[:, 0], np_X_norm[:, 1], c=np_Y,\n",
    "                                  s=20, edgecolor='k')\n",
    "    axarr[idx[0]].set_title(tt)\n",
    "\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "np_Y_pred = clf3up.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "np_Y_pred = clf4up.predict_proba(np_X_norm)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np_Y, np_Y_pred[:,1])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
    "                                   estimator_name='KNN')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F468vtVkynQA"
   },
   "source": [
    "**QUESTION 8**\n",
    "\n",
    "Vos modèles se généralisent-ils encore bien en 2012 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-29T10:42:50.756326400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP2_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
